---
title: "Generalized Linear Models in 3D"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Generalized Linear Models in 3D}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  message = F,
  warning = F
)
```

## Introduction

A multiple *linear* regression creates a flat regression surface. A multiple linear regression with an *interaction* term can be depicted as a curved regression surface with linear marginal effects. A *generalized linear model (glm)* takes a linear component as a variable in a nonlinear function, creating a curved regression surface with nonlinear marginal effects. 

This vignette demonstrates a binomial model and a Gamma model. 

* At this time, __regress3d__ has been tested on binomial models, negative binomials, and Gammas, but it should work for all generalized linear models. 
* Interaction terms are also allowed in the graphics for generalized linear regressions.
* The function `add_jitter()` is demonstrated in the example of a binomial glm. 

# Setup

The package regress3d is built on the syntax of plotly in R. Both libraries are called in the initial setup.

```{r setup}
library(regress3d)
library(plotly)
```


# Logistic Regression

## Data

The variables in the regression are county level measures from 2016. For pedagogical purposes, the variables are chosen to emphasize the s-shape of a logistic regression.

* `plurality_Trump16`: a binary variable indicating whether the plurality of a county voted for Trump in 2016.
* `any_college`: the percent of adults in the county that had ever enrolled in college, regardless of whether they graduated.
* `prcnt_black`: the percent of the county that identified as Black in the 2016 census. 

## 2D plot of a logistic regression

For reference, a two dimensional plot of logistic regression can look like this. 

* The outcome variable, `plurality_Trump16`, is binary. We use `ggplot2::geom_jitter()` to reveal the density of observations for counties that have very few Black residents. 
* In this case the explanatory variable `prcnt_black` is continuous. 
* A logistic regression model is specified to require an s-shape for the predicted probabilities so that they cannot exceed the range $(0,1)$.

```{r}
county_data %>%
  ggplot(aes(x = prcnt_black, y = plurality_Trump16)) +
  geom_jitter(width = 0, height = 0.1, alpha = 0.5) + 
  geom_smooth(method = "glm", method.args = list(family = "binomial")) +
  theme_classic()
```

## 3D plot of a logistic regression

The three dimensional plot adds education, `any_college`, to the logistic regression depicted above. 

```{r, out.width = "800px", out.height = "450px"}
mymodel <- glm(plurality_Trump16 ~ any_college+prcnt_black, 
               data = county_data, 
               family = "binomial")

plot_ly( data = county_data,
                        x = ~any_college,
                        y = ~prcnt_black,
                        z = ~plurality_Trump16) %>%
  add_jitter(, x_jitter = 0, y_jitter = 0, z_jitter = 0.1,
             size = 1, color = I('black'))%>%
  add_3d_surface(model = mymodel, ci = T) %>%
  add_marginals(model = mymodel, ci = T) 

```

## More on marginal effects

In a linear regression, the marginal effect of $x_1$ stays constant for all values of $x_2$. This is technically true for generalised linear models as well. However, note that for a given range of $x_1$, the magnitude of the change in the outcome $y$ can depend on the value of $x_2$. This is depicted in the image below, where the marginal effects of education ($x_1$)

```{r, out.width = "800px", out.height = "450px"}
plot_ly( data = county_data,
                        x = ~any_college,
                        y = ~prcnt_black,
                        z = ~plurality_Trump16) %>%
  add_jitter(, x_jitter = 0, y_jitter = 0, z_jitter = 0.1,
             size = 1, color = I('black'))%>%
  add_3d_surface(model = mymodel, ci = T) %>%
  add_marginals(model = mymodel, ci = T, omit_x2=T) %>%
  add_marginals(model = mymodel, ci = T, omit_x2 =T,
                x2_constant_val = 50) 


```

## Numeric regression results


```{r, results='asis', echo =F}
library(stargazer)

one_var_model <- glm(plurality_Trump16 ~ prcnt_black, 
               data = county_data, 
               family = "binomial")

two_vars_model <- glm(plurality_Trump16 ~ any_college+prcnt_black, 
               data = county_data, 
               family = "binomial")

stargazer(one_var_model, two_vars_model , type = 'html',
          keep.stat = c("n", "adj.rsq"),
          star.cutoffs = c(0.05),
          covariate.labels = c("County college experience","% Black", "Constant"),
          dep.var.labels = "plurality of county voted for Trump in 2016",
          dep.var.caption = "",
          model.numbers          = FALSE, 
          notes="<span>&#42;</span> p<0.05",
          notes.append=F)
```



# Gamma Model

## Data

## 2D code and graphic

For reference, a two dimensional plot of Gamma regression can look like this. 

* The outcome variable, `median_income16`, is continuous, positive, and right skewed. 

```{r}
county_data %>%
  ggplot(aes(x = any_college, y = median_income16)) +
  geom_point() + 
  geom_smooth(method = "glm", method.args = list(family = "Gamma")) +
  theme_classic()
```

## 3D code and graphic

The three dimensional plot adds `prcnt_black` to the Gamma regression depicted above. 

```{r, out.width = "800px", out.height = "450px"}
county_data$median_income16_1k <- county_data$median_income16/1000

mymodel <- glm(median_income16_1k ~ prcnt_black +any_college, 
               data = county_data, weight = pop_estimate16, family = Gamma)

p <- plot_ly( data = county_data,
              x = ~prcnt_black,
              y = ~any_college,
              z = ~median_income16_1k) %>%
  add_markers(size = ~pop_estimate16, color = I('black')) %>%
  add_3d_surface(model = mymodel)%>%
  add_marginals(model = mymodel) 

p
```



```{r, results='asis', echo =F, include=F, eval=F}
library(stargazer)
county_data$median_income16_1k <- county_data$median_income16/1000
one_var_model <- glm(median_income16_1k ~ any_college, 
               data = county_data, 
               # weight = pop_estimate16,
               family = "Gamma")

two_vars_model <- glm(median_income16_1k ~ prcnt_black +any_college, 
               data = county_data, 
               # weight = pop_estimate16,
               family = "Gamma")

stargazer(one_var_model, two_vars_model , 
          type = 'text',
          keep.stat = c("n", "adj.rsq"),
          star.cutoffs = c(0.05),
          covariate.labels = c("% Black", "County college experience", "Constant"),
          dep.var.labels = "County median income (&#36;1,000s)",
          dep.var.caption = "",
          model.numbers          = FALSE, 
          notes="<span>&#42;</span> p<0.05",
          notes.append=F)
```


```{r, out.width = "800px", out.height = "450px", eval = F, echo = F}
# mymodel <- glm(median_income16 ~ prcnt_black *any_college, data = county_data, family = Gamma)
# p <- plot_ly( data = county_data,
#               x = ~prcnt_black,
#               y = ~any_college,
#               z = ~median_income16) %>%
#   add_markers(size = ~pop_estimate16, color = I('black')) %>%
#   add_3d_surface(model = mymodel)%>%
#   add_marginals(model = mymodel) %>%
#   layout(
#     scene = list(
#       zaxis = list(range = c(0, 140000))))
```
